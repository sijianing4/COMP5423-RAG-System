
from google.colab import drive
import pandas as pd
from typing import Dict, Tuple, List
import os

class DataLoader:
    """æ•°æ®åŠ è½½å™¨ - å¤„ç†Google Driveä¸­çš„æ•°æ®æ–‡ä»¶"""
    
    def __init__(self):
        self.drive_mounted = False
        self.data_loaded = False
        self.train_df = None
        self.validation_df = None
        self.collection_df = None
        self.documents = []
        self.doc_ids = []
    
    def mount_drive(self) -> bool:
        """æŒ‚è½½Google Drive"""
        if not self.drive_mounted:
            try:
                drive.mount('/content/drive')
                self.drive_mounted = True
                print("âœ… Google DriveæŒ‚è½½å®Œæˆ")
                return True
            except Exception as e:
                print(f"âŒ Google DriveæŒ‚è½½å¤±è´¥: {e}")
                return False
        return True
    
    def load_hotpotqa_data(self, base_path: str = '/content/drive/MyDrive/RAGtest') -> Dict:
        """
        åŠ è½½HotpotQAæ•°æ®é›†
        
        Args:
            base_path: æ•°æ®æ–‡ä»¶åŸºç¡€è·¯å¾„
            
        Returns:
            Dict: åŒ…å«æ‰€æœ‰æ•°æ®çš„å­—å…¸
        """
        if not self.mount_drive():
            raise Exception("æ— æ³•æŒ‚è½½Google Drive")
        
        print("ğŸ“š åŠ è½½æ•°æ®...")
        try:
            self.train_df = pd.read_json(f'{base_path}/train.jsonl', lines=True)
            self.validation_df = pd.read_json(f'{base_path}/validation.jsonl', lines=True)
            self.collection_df = pd.read_json(f'{base_path}/collection.jsonl', lines=True)
            
            print(f"è®­ç»ƒé›†: {len(self.train_df)} æ ·æœ¬")
            print(f"éªŒè¯é›†: {len(self.validation_df)} æ ·æœ¬")
            print(f"æ–‡æ¡£é›†: {len(self.collection_df)} æ–‡æ¡£")
            
            # å‡†å¤‡æ–‡æ¡£é›†åˆ
            self.documents = []
            self.doc_ids = []
            for idx, row in self.collection_df.iterrows():
                if 'id' in row and 'text' in row:
                    self.doc_ids.append(row['id'])
                    self.documents.append(row['text'])
            
            print(f"æ–‡æ¡£åº“å¤§å°: {len(self.documents)} ä¸ªæ–‡æ¡£")
            self.data_loaded = True
            
            return {
                'train': self.train_df,
                'validation': self.validation_df,
                'collection': self.collection_df,
                'documents': self.documents,
                'doc_ids': self.doc_ids
            }
            
        except Exception as e:
            print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
            raise
    
    def get_sample_questions(self, num_samples: int = 3, split: str = 'train') -> List[str]:
        """
        è·å–ç¤ºä¾‹é—®é¢˜
        
        Args:
            num_samples: æ ·æœ¬æ•°é‡
            split: æ•°æ®é›†åˆ†å‰² (train/validation)
            
        Returns:
            List[str]: ç¤ºä¾‹é—®é¢˜åˆ—è¡¨
        """
        if not self.data_loaded:
            self.load_hotpotqa_data()
        
        df = self.train_df if split == 'train' else self.validation_df
        questions = []
        
        for i in range(min(num_samples, len(df))):
            if 'question' in df.columns:
                questions.append(df['question'].iloc[i])
            elif 'text' in df.columns:
                questions.append(df['text'].iloc[i])
        
        return questions
    
    def get_data_info(self) -> Dict:
        """è·å–æ•°æ®ä¿¡æ¯ç»Ÿè®¡"""
        if not self.data_loaded:
            self.load_hotpotqa_data()
        
        return {
            'train_samples': len(self.train_df),
            'validation_samples': len(self.validation_df),
            'collection_documents': len(self.collection_df),
            'train_columns': self.train_df.columns.tolist(),
            'validation_columns': self.validation_df.columns.tolist(),
            'collection_columns': self.collection_df.columns.tolist()
        }
